%\documentclass{sig-alternate-05-2015}
\documentclass[sigconf]{acmart}
\usepackage{url}
%\usepackage{arial}
\let\proof\relax
\let\endproof\relax
\usepackage{amsmath,amsfonts,amssymb,amsthm}
\usepackage{graphicx}
\usepackage{epsfig,multirow, color}
\usepackage{subfigure}
\usepackage{wrapfig}
\usepackage{psfrag}
\usepackage{algorithm}
\usepackage{latexsym}
\usepackage{algorithmic}

\theoremstyle{plain}
\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem*{cor}{Corollary}


%\theoremstyle{definition}
\newtheorem{defn}{Definition}
\newtheorem{conj}{Conjecture}
\newtheorem{exmp}{Example}

\theoremstyle{remark}
\newtheorem*{rem}{Remark}
\newtheorem*{note}{Note}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%  USE THIS? (To move table caption down)
 \usepackage{caption}
 %\captionsetup[table]{skip=5pt}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\usepackage{booktabs} % For formal tables
%\setcopyright{none}

\begin{document}

\title{Hardware Isolation Mechanisms for Security Improvement in FPGAs}
%
%\author{Festus Hategekimana}
%\affiliation{%
%  \institution{University of Arkansas}
%  \city{Fayetteville}
%  \state{AR}
%  \country{USA}}
%  \email{fhategek@uark.edu}
%
%\author{Taylor JL Whitaker}
%\affiliation{%
%  \institution{University of Arkansas}
%  \city{Fayetteville}
%  \state{AR}
%  \country{USA}}
%  \email{txw043@uark.edu}
%
%\author{Md Jubaer Hossain Pantho}
%\affiliation{%
%  \institution{University of Arkansas}
%  \city{Fayetteville}
%  \state{AR}
%  \country{USA}}
%  \email{mpantho@uark.edu}
%
%\author{Christophe Bobda}
%\affiliation{%
%  \institution{University of Arkansas}
%  \city{Fayetteville}
%  \state{AR}
%  \country{USA}}
%  \email{cbobda@uark.edu}


\begin{abstract}
Field Programmable Gate Arrays (FPGAs) platform security management continues to be a strong area of concern despite recent increased adoption and integration of FPGAs into commercial scale cloud computing systems. One of the technical problems in the FPGA security management area has been the lack of hardware primitives to support multi-tenancy while enforcing proper domain isolation. In this paper, we present a tutorial on recent progress that has been made to address this issue. Specifically, we present hardware isolation mechanisms that can be used to enable domain separation on FPGA based systems. We demonstrate the viability of these mechanisms through a software-hardware codesign implementing a simple TSL/SSL encryption application.
\end{abstract}


\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10002978.10003001.10003003</concept_id>
<concept_desc>Security and privacy~Embedded systems security</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10002978.10003001.10003599</concept_id>
<concept_desc>Security and privacy~Hardware security implementation</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10010583.10010600.10010628.10011716</concept_id>
<concept_desc>Hardware~Reconfigurable logic applications</concept_desc>
<concept_significance>500</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Security and privacy~Embedded Systems Security}
\ccsdesc[500]{Security and privacy~Hardware Security Implementation}
\ccsdesc[500]{Hardware~Reconfigurable Logic Applications}
\keywords{FPGA Security, Hardware Isolation, IP Containerization, CAPSL}


\maketitle


\section{INTRODUCTION}\label{sec:intro}
Many of today's critical embedded systems are increasingly relying on FPGA-based SoCs because of the useful balance between the performance, scale, flexibility, and rapid time to market they provide. This was recently exemplified with the recent Audi announcement that its 2018 A8 world's first Level 3 autonomous driving system will feature Altera's Cyclone FPGA SoCs for object and map fusion processing tasks. Though, it's not just in embedded systems space where we are seeing accelerated adoption of FPGA platforms, as they are also being continuously integrated into commercial scale cloud computing systems and data centers as evidenced by Amazon recent announcement of providing cloud compute instances with FPGAs (EC2 F1).

This increased adoption of FPGA into commercial scale cloud computing systems has highlighted the issue of FPGA's lack of hardware primitives, conceptually similar from a security perspective to a CPU's IO memory management unit (IOMMU), to support multi-tenancy while enforcing proper domain separation among the tenants (i.e. multiple applications utilizing the same FPGA) \cite{CloudFPGA}, \cite{CapslHOST}, \cite{Byma2014FPGAsIT}. This lack of native support for isolation creates security concerns where, since FPGA accelerators tend to run with full hardware access, a single accelerator vulnerabilities can be exploited through traditional system software stacks or if malicious, can bring down a shared compute host \cite{CloudFPGA}.

An effective solution to the problem of lack of proper domain separation on FPGAs should be able to enable scaling of security across a range of system parameters, such as power and performance, without significant drop in coverage. We believe and intend to demonstrate that this can only be achieved through some form of combination of measures that protect against hardware vulnerabilities directly at the hardware level and measures that enforce domain separation at the software level.

In this paper, we look at a set of  research works that individually attempted to address the problem of lack of isolation support on FPGAs. We demonstrate how certain elements of these works can be put together to provide an effective and comprehensive solution to this problem. Through a tutorial, we demonstrate the viability of this solution through a real-world software-hardware codesign application which implements a simple TSL/SSL encryption. The remainder of this paper is organized as follow: Section \ref{sec:threat_model} starts by describing the specific use case scenarios and security concerns this method addresses. Section \ref{sec:problem_definition} gives an overview of research works that form the basis of our comprehensive solution. Section \ref{sec:application} and Section \ref{sec:Implementation} conclude the paper with a tutorial demonstrating how a combination of the discussed approaches can be used to provide proper domain isolation on FPGA platform.


\section{THREAT MODEL} \label{sec:threat_model}

\begin{figure}[hbt]
\centering
\includegraphics[width=0.5\columnwidth]{figures/ThreatModel.pdf}
\caption{Threat Model: The adversary controls the FPGA SoC and can execute malicious code (non-trusted application + accelerator in red) remotely.}
\label{fig:threat}
\end{figure}

The illustration of our threat model in Figure \ref{fig:threat} shows the use case scenario our approach targets. We assume an adversary who can introduce hardware trojans in the IPs during development (supply chain attack). We assume this adversary has remote access to the FPGA system-on-chip (FPGA SoC) which contains some of the malicious IPs and is also aware of the trojans activation mechanisms (Trojans are not active and can only be activated externally by executing some malicious input for ex.). We assume the adversary may also control all the system software including the operating system. Our goal is to prevent unauthorized data access and modification by shielding non-trusted IPs execution into a hardware sandbox and providing secure isolated regions.

\section{HARDWARE ISOLATION MECHANISMS} \label{sec:problem_definition}

This section discusses current techniques that are employed to enforce hardware isolation on FPGAs. This list is by no means exhaustive and it is beyond the scope of this paper to discuss these techniques in greater details. The interested reader is encouraged to refer to cited works. 


\subsection{Reference Monitors}

In this approach, a hardware module or a microcontroller based firmware-upgradable module is used to monitor and enforce authorized sharing of system
resources among cores. Memory-access security policies are expressed in a specialized language, and a compiler translates these policies directly to a circuit (or a microcontroller) that enforces the policies. The circuit is then loaded onto the FPGA along with other components of the system.

There are many research efforts with some relation to this approach, but to the best of our current knowledge, works in \cite{HuffEmbedded} and in \cite{Huffmire} are the only work with similar goals that come close to ours here. In their work, they designed and implemented a reconfigurable reference monitor (RM) which implements an access control list (ACL). They then integrated the reference monitor into the on-chip peripheral bus (OPB) and used it to regulate access to the memory and peripherals. Memory and peripherals accesses go through a reconfigurable monitor's access control list [3]. The access control list associates every object (memory ranges for ex.) in the system with a list of principals (IP cores) with the rights of each principal to access the object[3]. In their implementation, each object access has to be computed by the reference monitor's ACL at runtime. The decision is either granted access or denied access. Since this access model can create potential memory performance issues in large memory applications, they proposed a mechanism in which a buffer is used to hold the data until the ACL grants approval of the legality of the request \cite{SPHuffmire}. Figure ~\ref{fig:ted} illustrates the implementation.For example, in case of a write, the data to be written is stored in the buffer until the ACL grants the approval, at which time the write request is sent to the memory \cite{SPHuffmire}.


\begin{figure}[hbt]
\centering
\includegraphics[width=0.75\columnwidth]{figures/ted_access.pdf}
\caption{Access Model Implementation. On the left, there's no "caching" mechanism. On the right, a buffer is used to hold the data while access rights are being looked up.} % The text in the square bracket is the caption for the list of figures while the text in the curly brackets is the figure caption
\label{fig:ted}
\end{figure}



Authors in \cite{FestusFCCM} observed that in Huffmire et al. access model implementation if you had consecutive and repeated memory access from the same ``principal" to the same ``object", each one of these requests would still have to go through the reference monitor's computation. This can potentially create performance issues in large designs. These issues can be avoided by adding the capability to remember access decisions. Authors in \cite{FestusFCCM} built upon this observation and proposed an improved implementation of this architecture by adding capability to remember access decisions to allow them to be administered at run-time without re-computations. Figure ~\ref{fig:access} shows their proposed access model.

\begin{figure}[hbt]
\centering
\includegraphics[width=1\columnwidth]{figures/access.pdf}
\caption{Improved Access Model Implementation.} % The text in the square bracket is the caption for the list of figures while the text in the curly brackets is the figure caption
\label{fig:access}
\end{figure}

Both of these techniques follow a similar design flow. Systems components are defined and implemented using hardware synthesis tools such as Xilinx's Vivado or Xilinx's XPS.  The hardware-enforced ACL core is generated by some policy compiler and it's then integrated with the rest of the system components similar to adding a standard custom IP to your design [CITAT],[CITAT]. In some instances, however, there can be compatibility issues. Sometimes standard integration of the ACL core can be complicated with the fact that some security-relevant attributes may not be directly available as parameters or easily derived from available parameters. For example, the current version of the AXI Interconnect IP core API available in Vivado 2016 does not present a component ID as a parameter. In situations like these, it's up to the application designer to build their own custom OPB (or AXI interconnect) IP which directly integrates this ACL security functionality.

Authors in \cite{proofcarrying}, \cite{proof}, \cite{proofcar} observed that the above described techniques assume a ``trusted" reference monitor to enforce the security policies and with no mechanism through which the platform itself can authenticate the authority of the reference monitor before it administers an access policy decision. The security concern here is that an attacker could conduct a man-in-the-middle attack on the system by inserting a malicious circuit inside the only authority entrusted with administrating shared resource access decisions. To mitigate this, they proposed an improved implementation of the reference monitor which combines the monitoring approach with a ``proof-carrying hardware" concept. Their approach consisted of using a consumer-producer approach, where a consumer specifies a desired functionality of the memory access monitor and sends this specification to the producer and the producer synthesizes this information into a bitstream \cite{proofcarrying}. The producer re-extracts the logic function from this bitstream and, together with the original specification, computes some miter function (which outputs an error flag if the specification and implementation differ for at least one input vector) \cite{proof}. This proof of reference monitor correctness is then generated along side with the bitstream and is sent to the consumer. The latter verifies the proof, and in case of success partially reconfigures the monitor with security policies \cite{proof}. The consumer verifies the proof of correctness from the producer by extracting the monitor's logic function from the bitstream and forms a miter in conjunctive normal form in the same way as the producer, but with the original specification. This new miter is compared to the producer's miter and if they both match, the implementation is accepted and the monitor is accepted. The monitor is rejected if the the miters do not match \cite{proof}, \cite{proofcar}.


\subsection{OS-Enforced Security: Zynq FPGA TrustZone}

In this approach, systems developers rely on an embedded operating system to provide system security services. Security features provided include, but are not limited to, confidentiality and integrity protection of the external memory containing the application code and data.

A recent example of this approach is the ARM TrustZone security architecture currently available to Zynq-7000 SoCs. In this example, the Xilinx Zynq-7000 processor system supports ARM TrustZone technology in both the PS and PL domain. The ARM TrustZone architecture makes trusted computing within the embedded world possible by establishing a trusted platform, a hardware architecture that extends the security infrastructure throughout the system design. Instead of protecting all assets in a single dedicated hardware block, the TrustZone architecture runs specific subsections of the system either in a ``normal world" or a ``secure world."

In the Zynq-7000 AP SoC, a normal world is defined as a hardware subset consisting of memory regions, L2 cache regions, and specific AXI devices. The Zynq-7000 AP SoC supports ARM TrustZone technology in both the PS and PL domains of the device. The PS provides a set of configuration registers related to TrustZone support for custom IPs. These configuration registers are then dynamically programmed by the software during execution. All slave IP cores instantiated in the logic can be individually assigned a Secure or Non-Secure designation. For Xilinx slave IP cores, Secure/Non-Secure configuration can be statically designated at the AXI interconnect level during system creation process.

Figure \ref{fig:ted} shows a simplified example of how to secure your design sensitive components from illegal hardware access using Zynq-7000 AP SoC TrustZone technology

\begin{figure}[hbt]
\centering
\includegraphics[width=1\columnwidth]{figures/TrustZoneHardware.pdf}
\caption{Improved Access Model Implementation.} % The text in the square bracket is the caption for the list of figures while the text in the curly brackets is the figure caption
\label{fig:trustzone}
\end{figure}

In this example, also available in [], on the hardware level the PL domain uses two custom master IP cores:

\begin{itemize}
\item \textbf{Secure Custom IP:}
This performs Secure read/write transactions to DDR using the HP slave port in the PS. It is also connected to the Application Processor Unit (APU) via a GP master port for register configuration.
\item \textbf{Non-Secure Custom IP:}
This is used to perform read/write transactions from/to the PS DDR upon requests from the external world. It performs Non-Secure read transactions to DDR using an HP slave port. Configuration of this IP is done by the PS processor through a GP master port.
\end{itemize}

Upon power-on, the PS processor initializes both custom IPs, configures registers to establish Secure and Non-Secure regions in DDR memory, and transfers private data/instructions to the Secure DDR region. After initialization and upon receiving a data request from the external interface, the
Non-Secure custom IP first copies the data from the external interface to the Non-Secure region of DDR memory. It then interrupts the PS processor, which commands the Secure custom IP to perform the appropriate data computations using its private data/instructions in conjunction with the data just copied to the Non-Secure region of DDR memory. After computation is completed, Secure custom IP puts the computed data into the Non-Secure DDR region and interrupts the PS processor to command the Non-Secure custom IP to start transferring data from the requested location.

On the software level, application processes (and their IPs) with non-secure status designation execute in memory space separated from processes with secure status designation. When a user process running in the Non-Secure world requires Secure execution, it makes a request to the Non-Secure kernel to enable the TrustZone Secure Monitor to transfer execution of the process to the Secure world. The Secure Monitor mode links the two zones and acts as a gatekeeper to manage program flow between them.

To ensure integrity of the TrustZone software, Zynq-7000 provides a secure boot flow; where the on-chip BootROM code starts the whole security chain by ensuring that first-stage bootloader (FSBL) is signed and verified.

\subsection{CAPSL: Automatic Generation of Hardware Sandboxes}\label{sec:CAPSL}
The approach of utilizing hardware sandboxes for isolating and identifying potential malicious IP-internal circuits provides a flexible design process for systems designers and integrators. Similar to discussed approaches, a sandbox isolates IP by partioning the hardware design to a trusted secure region and a non-trusted environment contained within the sandbox. Hardware sandboxing allows the placement of an interface-level reference monitor to ensure the integrity of non-trusted IP interactions. In addition, virtual resources can be provided to protect critical system resources. The sandbox approach allows unrestricted access to resources used by the trusted IP, while containing potential negative effects of untrusted components behind a behavioral monitor and resource virtualization.

CAPSL, the Component Authentication Process for Sandboxed Layouts supplies automation for generating hardware sandboxes, allowing for a streamlined integration of questionable components into secure systems. The design flow is summarized in the following tasks:

\subsubsection{Construct Internal IP Interface Models:}
A specification defining the interface and its behavior is required for each IP in order to formally model the IP and generate automata objects of each policy. The set of automata produced from all policies is used as a behavioral monitor within the sandbox. The specification enables the flexibility to define behavior at varying levels of abstraction and varying degrees of completeness. To elaborate, specification might contain partial interface defintions and/or behaviors abstracted through additonal computation logic. To capture security properties, CAPSL adopts the Interface Autoamta (IA) formalism of De Alfaro and Hetzinger [CITATION NEEDED] along with a subset of the Properties Specification Language (PSL), Sequential Extended Regular Expression (SERE) [CITATION NEEDED]. As a baseline requirement, interface layouts are required (IP interface inputs, outputs). Beyond this, any combination of IA-based descriptions of allowed behavior, explicitly denied interactions defined as SERE statements, and computational logic is allowed.


\subsubsection{Optimize Models:}
We chose IA as our internal model due to its capability to handle \textit{composition} and \textit{refinement}. While composition insures that two communicating components do not perform illegal actions, i.e one automaton produces an input that the other cannot consume, refinement allows breakdown within component boundary while still maintaining the compatibility. The sandbox design leverages these two properties to provide compatible and secure interfaces between the IP and the rest of the system through the sandbox. Applying the composition operation of IA requires the environment (the IP in our case) not to perform illegal actions, i.e. actions that the sandbox and therefore the rest of  the system doesn't expect. This means that interfaces are assembled only if they are compatible, resulting in a new composed interface. With all policies respresented as Interface Automata, the composition operation can supply an avenue for reducing the policy automata set size through merging automata with consideration for the environmental assumptions of it.


\subsubsection{Generate/Package Sandbox IP:}
The resulting optimized set of policies can now be translated to a reference monitor. When translating from a formal model, it is possible to insert a variety of target IP implemetnations for generating the sandbox as an IP. Initial development of CAPSL produced the sandbox as Vivado IP implemented as VHDL. CAPSL, using a VHDL flow, generates a ``checker" module. The module is generated by one-hot encoding our monitoring automatons as VHDL statements which capture the expected behavior of the IP. The checker module is combined together with virtual resources (BRAMs, SLRs, etc.) to generate the core logic which governs the sandbox. The generated core logic is then combined with a sandbox controller (routing all signals between interfaces and checker) to conclude the sandbox generation. The controller consists of the sandbox interface (composed with the non-trusted IP interface), physical interface, some status registers, and a multiplexer which acts as a switch to either allow IP interactions to continue or to invalidate them.



\section{SECURITY CRITICAL EXAMPLE APPLICATION} \label{sec:application}

In this section, we introduce an example application to demonstrate the various hardware isolation methods discussed above. Each of the methods has unique strengths and a more comprehensive security profile can be realized upon implementing each in conjunction. We propose a system that performs secure encryption processes (via Hardware-enfored Access Lists and TrustZone) alongside potentially malicious non-secured processes. With our secure process utilizing hardware-accelerated encryption, CAPSL is utilized to secure the encryption engine and enforce the integrity of its behavior. This system suits the implementation of the discussed hardware isolation methods with the inclusion of points of attack in both software and hardware. Below, we detail the example application and address the security vulnerabilites with regard to the introduced isolation methods.


\subsection{Overview}

We intend to demonstrate the steps required to ensure the protection of a general security-critical system design with an SoC system providing reconfigurable fabric along with a co-processor. The discussed isolation methods enforce security at the OS/PS level down to the hardware IP interface level. Thus, our demonstration application includes process level applications running on the processing system while hardware is utilized for acceleration cores. The system requires a security critical application such an application requiring sensitive keys to be handled at the software level while relying on hardware for accelerating cryptographic functions.

\subsubsection{Secure Echo Server Process:}
We utilize an echo server that encrypts client communcations with a session key established through a simplified TLS/SSL handshake. This system setup assumes the server to be run on the SoC device targeted for protection while the client is run on a remote machine. The SoC hosting the echo server is designed to run on a Zynq SoC, with the zynq processor hosting a Linux OS and utilizing FPGA area for cryptographic functions. The echo server process and complementing client process are implemented as Python programs. We used Xilinx's Petalinux tool for generating the design images required to boot a Linux OS and mount the filesystem. We implemented our system on a Digiglent Zybo [IT MIGHT NOT BE BIG ENOUGH for AES + RSA]...

To further elaborate on our application, we begin with the echo server process. The its initial state, the server process listens on a specified network IP address and port awaiting a client connection. Upon receiving a connection, a handshake is initiated as the server immediately shares an RSA public key. A session key computed by the client is received by the server encrypted with its public RSA credentials. Deciphering this session key allows subsequent communications to be secured, namely the server's acknowledgement of a successful handshake, the client's message, and finally the server's echoed message. This system behavior as seen at the process level can be seen in [NEED DIAGRAM].

\subsubsection{Hardware Accelerated Encryption Engine:}
The handshake requires the use of both symmetric-key and public-key algorithms, as a symmetric-key (used as session key) is generated from utilizing a asymmetric-key to encrypt and publically transmit the session key. AES and RSA are commonly used to meet these requirements. As these can be computationally expensive with larger key sizes, one standard application of hardware acceleration is for performance boosts with cryptographic functions. To provide our demo system with a hardware component, an AXI-bus enabled IP core is used to accelerate the AES and RSA algorithms used by the echo server process. The PS and PL interaction is detailed in [NEED DIAGRAM].

Upon requiring the AES or RSA cores during execution, data is first written to the appropriate input data registers for each IP. After a successful write of input data, an enable signal is written to a control register to signal the IP core to perform the encryption/decryption. A set of output data registers are assigned to each core along with a status register to inform the software process of a complete computation.

The hardware cores were implemented as Vivado IP cores and exposed by supplying an AXI-bus interface for reading inputs and writing outputs to DDR memory. This is accessible by default from the OS as Petalinux images include kernel drivers for exposing DDR memory under the OS's '/dev/mem' filepath. The memory blocks for the cryptographic core are accessible via their device-tree specified address. This will be revisited later in [POSSIBLY ANOTHER SECTION TO GO DEEP INTO DETAIL].




\subsection{Security Vulnerabilities}

Our application was designed to include vulnerabilities that could be found in designs that include software processes and hardware accelerators handling sensitve information without security measures. An operating system lacking the ability to restrict executions on sensitive data to isolated processor environments and verify process permissions for secured memory space creates potential points of attack for malicious processes. With the hardware design community's growing adoption rate of third-party IP cores, there are a multitude of infiltration points within the development and manufacturing process with which malicious parties have been able to exploit. It should be noted that it is recognized the server/client handshake is missing vital components of a true TLS/SSL scheme such as certificate based verifications performed by both client and server. However, the scope of this work omits the undertaking of securing the network layer.

To exploit the vulnerabilities mentioned, we have included a non-secure process and hardware trojan for the purpose of demonstration and providing a metric of system security strength.

\subsubsection{Software Threat Insertion:}
[SECTION ABOUT A NONSECURE PROCESS INTENDED TO ACCESS SENSITVE DATA]


\subsubsection{Hardware Threat Insertion:}

Our encryption engine is a prime candidate for inserting a malicious circuit as it will have access to sensitive encryption key data. As our application performs a simple handshake and utilizes both AES and RSA algorithms, we can leverage the Trust-hub.org repository of hardware trojans for AES128 and BasicRSA.

Both AES128 and Basic RSA trojan classes contain variations of activation methods, from always-on trojans to internal condition triggers. We chose the following trojans...


\subsection{Adressing Vulnerabilities with Isolation}
An accepted paradigm of security for our proposed system would require secure execution for sensitive computations with dedicated hardware resources that are deemed secure. We address the system vulnerabilities as follows:


\subsubsection{Reference Monitor and TrustZone:}
[FESTUS]

\subsubsection{Hardware Sandboxing:}
The protections put in place with HACLs and Trustzone are limited as they do not consider malicious hardware components interacting with secure processes. Though the process execution environment may be secured with relevant memory blocks protected, an assumed-secure IP core could house a malicious hardware trojan.

To complement the methods discussed for secure process execution, we propose the use of CAPSL to extend policy-driven and isolation-based security to the programmable logic of an SoC. We have addressed all components of our demo systems with the exception of our cryptographic hardware cores. With the security-critical server/client processes utilizing hardware cores, it is essential that the IP are behaving as expected. Hardware sandboxing provides a way to safely integrate nontrusted IP into a secure system. By securing the cores within a sandbox, we are able to monitor all nontrusted IP interface interactions and isolate unexpected interctions with secured resources.





\section{IMPLEMENTING ISOLATION} \label{sec:Implementation}
In this section, we discuss implementation details reagrding the steps of applying the isolation methods.

\subsection{Reference Monitor}

\subsection{TrustZone}

\subsection{CAPSL}

As discussed in Section \ref{sec:CAPSL}, the CAPSL design flow requires specifications for nontrusted IP (Cryptographic cores) purposed for defining interface connections and behavior. The IP models resulting from specification are then subjected to an optimization phase. The collection of models are translated to a reference monitor implementation following optimization. The final output is an implementation of the hardware sandbox packaged as an IP.

\subsubsection{IP Specification:}

To utilize CAPSL's sandbox generation process, we must define the IP we wish to include. Due to the underlying modelling of the untrusted IP, specification at the interface level, or any abstraction of this, is required. That is, specification might contain partial interface defintions and/or behaviors abstracted through additonal computation logic. The specification files for AES and RSA cores are explained in Figure [RSA AND AES SPEC FILES EXPLANATION DIAGRAM].

Along with the required interface layout definition, the specifications for both AES and RSA utilize SERE statements in conjunction with addition computational logic to provide explicitly denied interactions. More specifically, the specifications are utilizing additonal logic for abstracting the SERE specifications for detecting known trojan triggers. The RSA specification also utilizes the IA-based description of allowed behavior to define how the IP shares its current state.


\subsubsection{Model Optimization:}

\subsubsection{Sandbox Generation:}




%Our proposed design is a hardware-software solution. Figure ~\ref{fig:proposed_design} illustrates our design processing flow and partitions.
%
%\begin{figure} [H]
%\centering
%\includegraphics[width=.9\linewidth]{FPLDiagram2.pdf}
%\caption{Proposed Design}
%\label{fig:proposed_design}
%\end{figure}
%
%First, hand-written multi-digit numbers images in RGB (Red, Green, and Blue) format are supplied to the system through some camera input. Then, we apply grayscaling to get a monochromatic image. The reason behind this is, for this particular class of problem, the color information is not relevant as much as the luminosity. To attenuate potential illumination variances and differences in the background, we applied thresholding. The result is a binary image that we then proceed to store in the memory. This part is implemented in hardware.
%
%In the software portion, we first fetch the binary image from the memory. Then, we extract each individual digit from left to right. Each extracted image array is then downsampled into a 28x28, the same size of MNSIT images, binary image that we then feed into the perceptron. The latter, previously trained offline with the MNIST data set, classifies each digit and then reconstruct the original number.
%
%\subsection{Digit Extraction Process}
%
%
%First step of multi-digit prediction algorithm is to successfully extract each digit. Many of the existing methods use segmentation and complex features extraction in order to extract individual digits from the numeral string. In our work, we implemented a different and computationally efficient approach to extract digits. To detect the start of each digit, the system scans through each of the column from left to right looking for first non-zero column that indicates the start point of a digit. After detecting the starting point,  the system looks for the first all zero column in the image. This column indicates the end boundary of that digit. Within these two columns the system scans through the rows to attain the row boundaries of that hand written digit.  The pixel values between these four points are then copied to another n28xn28 (n=1,2,3...) size image. Digit in the new image is then down-sampled by n to fit in a 28x28 image. The search for the next digit starts from the previously found all zero column. Figure ~\ref{fig:digitExtract} provides a visual illustration of our digit extraction process.
%
%\begin{figure} [hbt]
%\centering
%\includegraphics[width=.8\linewidth]{extract.pdf}
%\caption{Visual illustration of digit extraction process}
%\label{fig:digitExtract}
%\end{figure}
%
%The MNIST database we used to train our MLP was constructed from NIST's Special Database 3 and Special Database 1; which contain binary images of handwritten digits. These images were then centered in a 28x28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field. This constrained us to also map the extracted digits to the center of a 28x28 image in order to achieve good performance in our MLP.
%
%
%\subsection{Digit Recognition Process}
%
%Before we discuss the digit recognition process, let's first discuss how we trained the perceptron.
%
%\subsubsection{Training on  MNIST Dataset}
%The MNIST dataset used in this work has a training set of 60000 and a test set of 10000 handwritten digits (each has 28x28 grayscale pixels, each being represented by 8 bits) \cite{726791}. Figure \ref{fig:sampledigit} shows a random sample of this dataset.
%
%\begin{figure} [hbt]
%\centering
%\includegraphics[width=0.5\linewidth]{MNIST_sample.pdf}
%\caption{Sample MNIST digits}
%\label{fig:sampledigit}
%\end{figure}
%
%As we discussed in section \ref{regularization}, the end goal of a neural network design is to obtain a network that performs well on inputs not encountered during training \cite{726791}. To achieve this, we empirically found out, through trial and error, that three layers with neurons are good enough to achieve generalization. Figure~\ref{fig:neural_net} shows the neural network model we implemented. It is a 3 layers neural network. The input layer has 300 neurons, each neuron takes 784 pixels of the handwritten digit image as input. The subsequent layers have 100 and 10 neurons, respectively. The 10 output neurons will be activated proportionally to the network prediction.
%
%\begin{figure} [hbt]
%\centering
%\includegraphics[width=0.85\linewidth]{neural-network.pdf}
%\caption{ The implemented neural network. It consist of three layers- an input layer with 300 neurons, an output layer with 10 neurons and a hidden layer comprising 100 neurons. Each neuron in the input layer takes 784 pixels of image data. The activation function used in all the layers is hyperbolic tangent.}
%\label{fig:neural_net}
%\end{figure}
%
%We trained our MLP with stochastic gradient descent and backpropagation on the 60000 instances of the training set. All input values were normalized by a division by 256. The learning rate was set to 0.01 and it decreased by a factor of 0.997 after every epoch of training. This is because if the learning rate is very small, it takes many steps to get to the optimum. However, if the learning rate is too big, it is possible to diverge instead of converge. We found that a learning rate of 0.01 was fast enough for the system to converge. The weights and bias are initialized to small random values picked from a normal distribution. The L1 regularization decay is set to 0.0001. Figure \ref{fig:misses} shows the evolution of the training procedure over each epoch. The MLP was trained on a 3.10GHz 64bit IntelÂ® Core i5-2400 processor with 12GB RAM. The MLP best performance was found to be 324 misses out of 10000 training data, with approximately 1.2 hours training time. Although, a missing rate of 3.24\% is a few points up compared to the state-of-the art, in the context of the target application, it is still a solid performance for a client-side solution that do not rely on powerful servers and many hours of training.
%
%
%\begin{figure} [hbt]
%\centering
%\includegraphics[width=0.85\linewidth]{misses.pdf}
%\caption{MLP Training with L1 and L2 is shown. Both optimization methods are also compared to MLP training without regularization. }
%\label{fig:misses}
%\end{figure}
%
%\subsection{Design Implementation}
%We implemented our design on the Zybo, a development board for the Zynq MPCore FPGA. The latter is a programmable logic ( Zynq PL) coupled with a diffused 650Mhz dual-core Cortex-A9 processor (Zynq PS) \cite{xilinxzynq}. Figure \ref{fig:proposedArchitecture} illustrates our implementation.
%
%\begin{figure}
%\centering
%\includegraphics[width=1\linewidth]{FPLDiagram.pdf}
%\caption{SoC Implementation of the hand-written digit numbers recognition system.}
%\label{fig:proposedArchitecture}
%\end{figure}
%
%The application works as follow: The camera interface IP takes a 640x480 image input in RGB format from the camera. The camera used in our system is low voltage CMOS image sensor that provides full functionality of a single-chip VGA camera and image processor. Camera parameters are configured using I2C protocols. It transmits half of an 16-bit RGB (5:6:5) pixel during one pixel clock cycle. Capture block latches the first half and the second half together to produce a 16 bit RGB data.
%
%The RGB to-Grayscale IP takes RGB data as input and converts them into grayscale images (8-bit data). The luminosity formula to convert RGB triplets to gray-scale is traditionally $Y=0.2126R+0.7152G+0.0722B$ . In our design, in order to avoid the use of floating point operations in FPGA, we simplified the formula to $Y=0.25R+0.5G+0.12B$  where these fraction values of RGB data can easily be obtained by right shifting operations. This enabled us to obtain increased performance without losing digit extraction accuracy.
%
%To attenuate illumination variances and differences in the background, we applied thresholding operation. The MNIST dataset is composed of bright digits written over a dark background. This means that the pen strokes have positive integer values near 255 and the background is always 0. To better approximate this scenario, The threshold IP core is used to read these grayscaled pixels and convert the image into a binary image. Equation \ref{eq:threshold} illustrates the precise operation.
%
%
%\begin{equation} \label{eq:threshold}
%Y' = \left\{
%  \begin{array}{l l}
%    0 & \quad \text{if $Y>T$}\\
%   255-Y & \quad \text{if $Y\leq T$}
%  \end{array} \right.
%\end{equation}
%
%Following the thresholding, the binary image is then downsampled by two. This step reduces the image size from 640x480 to 320x240. The reason to do so is to reduce the amount of data transfer from PL to PS. We have seen that this downsampling of image does not degrade the performance of the MLP. Further, it means that the rest of the system will require less pixels to process. These image frames are then fed into a AXI Video DMA ipcore. This ipcore writes the image frames into the memory. We implemented the digit extraction and detection tasks on the software when we realized they were not going to fit on the device if implemented as hardware blocks.
%
%On the software side, the Zynq processor of Zybo reads the binary image frames from the memory and extracts the digits in the right order. The extracted digits are then fed into our trained neural network for prediction. The trained weights obtained after the offline training procedure are then hard coded into C++ header files. The software part of the algorithm is written in C++ and cross compiled with GCC.
%The image frames are read back from the memory using AXI4-Stream to Video Out IP core which serves to convert AXI4-Stream data into 24 bit RGB format. The latter is then formatted and sent out to the on board VGA ports for display.

%\section{Evaluation} \label{sec:results}
%
%This section starts with a discussion on the resource utilization of our implementation. This is then followed with a discussion on how our SoC implementation performance compares to software only implementations and a discussion on the execution time analysis of our implementation.
%
%\subsection{Resources Overhead}
%
%
%Table ~\ref{tab:resources} shows the device resources utilization and the power consumption of the designed prototype.
%
%\begin{table} [H]
%\caption{RESOURCES UTILIZATION} \label{tab:resources}
%\begin{minipage}[b]{\linewidth}
%\renewcommand{\arraystretch}{0.6}
%\addtolength{\tabcolsep}{-2.7pt}
%\renewcommand{\thefootnote}{\thempfootnote}
%\renewcommand{\thempfootnote}{\fnsymbol{mpfootnote}}
%\begin{center}
%\begin{tabular}{ c | c | c  }
% \textbf {RESOURCE} & \textbf{AVAILABLE} & \textbf {USAGE}\\
%\midrule
%\midrule
%\ LUTs             &    17600      \ & 3738      \ \\
%%\hline
%\ LUTRAMs          &    6000       \ & 463       \ \\
%%\hline
%\ BRAMs            &    60         \ & 2        \ \\
%%\hline
%\ Dyanimc Power    &    -          \ & 1.715W    \ \\
%
%\ Total On-Chip Power     &    -   \ & 1.851W    \ \\
%\end{tabular}
%\end{center}
%\end{minipage}
%\end{table}
%
%\subsection{Performance}
%
%We evaluated the performance of our SoC implementation by presenting it with random series of non-overlapping three digits and four digits numbers. Our system detected all of them. We expect our system to maintain close to 96.76\% detection accuracy as long as there's at least one all-zeroes column gap between two consecutive digits.  As part of our evaluation process, we also looked at our system's reaction time, the time it takes our system to correctly detect the numbers. The measurements were conducted on a 650MHz frequency Zynq diffused processor. Table \ref{tab:timing} summarizes the results.
%
%\begin{table} [H]
%\caption{PERFORMANCE OVERHEAD} \label{tab:timing}
%\begin{minipage}[b]{\linewidth}
%\renewcommand{\arraystretch}{0.6}
%\addtolength{\tabcolsep}{-2.7pt}
%\renewcommand{\thefootnote}{\thempfootnote}
%\renewcommand{\thempfootnote}{\fnsymbol{mpfootnote}}
%\begin{center}
%\begin{tabular}{ c | c | c }
%%\hline
% \textbf {TASK} & \textbf{With HW IPs} & \textbf{W/Out HW IPs} \\
%\midrule
%\midrule
%\ Avg. extraction time/digit       &0.29 ms    &0.29 ms      \ \\
%%\hline
%\ Avg. prediction time/digit       &2.8 ms     &2.8 ms       \ \\
%%\hline
%\ Avg. execution time/digit        &2.91 ms    &7.18 ms      \ \\
%%\hline
%\end{tabular}
%\end{center}
%\end{minipage}
%\end{table}
%
%
%As table \ref{tab:timing} shows, the average time it take to extract and predict a digit stays the same whether this is done with software-hardware implementation or just software. The software-hardware implementation picks up speed-up gains (x2.47) from performing initial image processing operations into hardware. These initial image processing operations were important to our solution since they allowed us to avoid the use of computationally expensive approaches like segmentation to extract the digits.
%


\section{Conclusion} \label{sec:conclusion}

% This paper presents the first FPGA SoC implementation solution to the hand-written multi-digit numbers recognition problem. We demonstrated  a novel digit extraction method which rely on identification of images' non-zeros columns instead of the widely used computationally-expensive segmentation method, and also discussed how we employed a multi-layer neural network. The paper presents a design and an FPGA implementation of the proposed solution; and also discusses various optimization techniques in the neural network implementation that lead to increased performance. Our future work will explore the possibility of implementing the digit extraction part on the FPGA.


\bibliographystyle{ACM-Reference-Format}
\bibliography{FPGA2018}

\end{document}
